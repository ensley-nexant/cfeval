% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/results.R
\name{results}
\alias{results}
\title{Create a causal forest results object}
\usage{
results(fit, preds = NULL)
}
\arguments{
\item{fit}{A trained causal forest object from
\code{\link[grf]{causal_forest}}}

\item{preds}{Out-of-bag training predictions from \code{fit}, If omitted,
they will be generated, but this will slow down the function significantly.}
}
\value{
A \code{\link[dplyr:reexports]{tibble}} containing the following columns:
\describe{
\item{\code{W}}{The original treatment assignments.}
\item{\code{W.hat}}{The estimated treatment propensities:
\eqn{\hat{W} = E[W | X]}{W.hat = E[W | X]}.}
\item{\code{Y}}{The original outcome variable.}
\item{\code{Y.hat}}{The expected response estimates, marginalized over
treatment: \eqn{\hat{Y} = E[Y | X]}{Y.hat = E[Y | X]}.}
\item{\code{treatment}}{The treatment
assignments as a factor, "Control" or "Treated". This looks better in plots
than \code{W} does.}
\item{\code{cate}}{The conditional average treatment effect (CATE) estimates}
\item{\code{cate.se}}{The standard errors of the CATEs.}
\item{\code{debiased.error}}{An estimate of the error obtained if the forest had
an infinite number of trees.}
\item{\code{excess.error}}{A jackknife estimate of how unstable the estimates are
if forests of the same size were repeatedly grown on the same data set.}
\item{\code{IPW}}{The inverse propensity weights: \eqn{\frac{1}{\hat{W}}}{1 / W.hat}
if \eqn{W = 1}, \eqn{\frac{1}{1 - \hat{W}}}{1 / (1 - W.hat)} otherwise.}
\item{\code{bias}}{A measure of each observation's contribution to the overall
bias of the model, relative to a simple difference in means.}
}
}
\description{
Having the out-of-bag prediction results in a tidy, tabular format makes
visualization much easier.
}
\details{
\code{debiased.error} and \code{excess.error} serve to partition the overall prediction
error into two parts. \code{debiased.error} is "irreducible" error in a sense because it
cannot be made smaller by increasing the number of trees in the forest. \code{excess.error}
can, however. The \link[grf:predict.causal_forest]{grf authors recommend} growing
enough trees that \code{excess.error} becomes negligible.
}
\examples{
\dontrun{
 require(grf)

 Xdat <- subset(cfex, select = -c(W, Y))
 X <- make_contrasts(Xdat, 'fct')
 cf <- causal_forest(X, cfex$Y, cfex$W)

cf_eval(cf, Xdat)$res
}

}
\seealso{
\url{https://grf-labs.github.io/grf/articles/diagnostics.html#assessing-fit}
for a discussion of the bias measure and how it is calculated.
}
